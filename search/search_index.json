{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introducing Whisper-TikTok \ud83e\udd16\ud83c\udfa5","text":""},{"location":"#table-of-contents","title":"Table of Contents","text":"<ul> <li>Introduction</li> <li>Video (demo)</li> <li>How it works?</li> <li>Web App (Online)</li> <li>Streamlit Web App</li> <li>Local Installation</li> <li>Dependencies</li> <li>Web-UI (Local)</li> <li>Command-Line</li> <li>Usage Examples</li> <li>Additional Resources</li> <li>Code of Conduct</li> <li>Contributing</li> <li>Upcoming Features</li> <li>Acknowledgments</li> <li>License</li> </ul>"},{"location":"#introduction","title":"Introduction","text":"<p>Discover Whisper-TikTok, an innovative AI-powered tool that leverages the prowess of Edge TTS, OpenAI-Whisper, and FFMPEG to craft captivating TikTok videos. Harnessing the capabilities of OpenAI's Whisper model, Whisper-TikTok effortlessly generates an accurate transcription from provided audio files, laying the foundation for the creation of mesmerizing TikTok videos through the utilization of FFMPEG. Additionally, the program seamlessly integrates the Microsoft Edge Cloud Text-to-Speech (TTS) API to lend a vibrant voiceover to the video. Opting for Microsoft Edge Cloud TTS API's voiceover is a deliberate choice, as it delivers a remarkably natural and authentic auditory experience, setting it apart from the often monotonous and artificial voiceovers prevalent in numerous TikTok videos.</p>"},{"location":"#streamlit-web-app","title":"Streamlit Web App","text":""},{"location":"#demo-video","title":"Demo Video","text":"<p>https://github.com/MatteoFasulo/Whisper-TikTok/assets/74818541/68e25504-c305-4144-bd39-c9acc218c3a4</p>"},{"location":"#how-it-works","title":"How it Works","text":"<p>Employing Whisper-TikTok is a breeze: simply modify the video.json. The JSON file contains the following fields:</p> <ul> <li><code>series</code>: The name of the series.</li> <li><code>part</code>: The part number of the video.</li> <li><code>text</code>: The text to be spoken in the video.</li> <li><code>outro</code>: The outro text to be spoken in the video.</li> <li><code>tags</code>: The tags to be used for the video.</li> </ul> <p>Summarizing the program's functionality:</p> <p>Furnished with a structured JSON dataset containing details such as the series name, video part number, video text and outro text, the program orchestrates the synthesis of a video incorporating the provided text and outro. Subsequently, the generated video is stored within the designated <code>output</code> folder.</p> Details  The program conducts the **sequence of actions** outlined below:  1. Retrieve **environment variables** from the optional .env file. 2. Validate the presence of **PyTorch** with **CUDA** installation. If the requisite dependencies are **absent**, the **program will use the CPU instead of the GPU**. 3. Download a random video from platforms like YouTube, e.g., a Minecraft parkour gameplay clip. 4. Load the OpenAI Whisper model into memory. 5. Extract the video text from the provided JSON file and initiate a **Text-to-Speech** request to the Microsoft Edge Cloud TTS API, preserving the response as an .mp3 audio file. 6. Utilize the OpenAI Whisper model to generate a detailed **transcription** of the .mp3 file, available in .srt format. 7. Select a **random background** video from the dedicated folder. 8. Integrate the srt file into the chosen video using FFMPEG, creating a final .mp4 output. 9. Upload the video to TikTok using the TikTok session cookie. For this step it is required to have a TikTok account and to be logged in on your browser. Then the required `cookies.txt` file can be generated using [this guide available here](https://github.com/kairi003/Get-cookies.txt-LOCALLY). The `cookies.txt` file must be placed in the root folder of the project. 10. Voila! In a matter of minutes, you've crafted a captivating TikTok video while sipping your favorite coffee \u2615\ufe0f."},{"location":"#web-app-online","title":"Web App (Online)","text":"<p>There is a Web App hosted thanks to Streamlit which is public available in HuggingFace, just click on the link that will take you directly to the Web App.</p> <p>https://huggingface.co/spaces/MatteoFasulo/Whisper-TikTok-Demo</p>"},{"location":"#local-installation","title":"Local Installation","text":"<p>Whisper-TikTok has undergone rigorous testing on Windows 10, Windows 11 and Ubuntu 23.04 systems equipped with Python versions 3.8, 3.9 and 3.11.</p> <p>If you want to run Whisper-TikTok locally, you can clone the repository using the following command:</p> <pre><code>git clone https://github.com/MatteoFasulo/Whisper-TikTok.git\n</code></pre> <p>However, there is also a Docker image available for Whisper-TikTok which can be used to run the program in a containerized environment.</p>"},{"location":"#dependencies","title":"Dependencies","text":"<p>To streamline the installation of necessary dependencies, execute the following command within your terminal:</p> <pre><code>pip install -U -r requirements.txt\n</code></pre> <p>It also requires the command-line tool FFMPEG to be installed on your system, which is available from most package managers:</p> <pre><code># on Ubuntu or Debian\n\nsudo apt update &amp;&amp; sudo apt install ffmpeg\n\n# on Arch Linux\n\nsudo pacman -S ffmpeg\n\n# on MacOS using Homebrew (&lt;https://brew.sh/&gt;)\n\nbrew install ffmpeg\n\n# on Windows using Chocolatey (&lt;https://chocolatey.org/&gt;)\n\nchoco install ffmpeg\n\n# on Windows using Scoop (&lt;https://scoop.sh/&gt;)\n\nscoop install ffmpeg\n</code></pre> <p>Please note that for optimal performance, it's advisable to have a GPU when using the OpenAI Whisper model for speech recognition. However, the program will work without a GPU, but it will run more slowly. This performance difference is because GPUs efficiently handle fp16 computation, while CPUs use fp32 or fp64 (depending on your machine), which are slower.</p>"},{"location":"#web-ui-local","title":"Web-UI (Local)","text":"<p>To run the Web-UI locally, execute the following command within your terminal:</p> <pre><code>streamlit run app.py --server.port=8501 --server.address=0.0.0.0\n</code></pre>"},{"location":"#command-line","title":"Command-Line","text":"<p>To run the program from the command-line, execute the following command within your terminal:</p> <pre><code>python main.py \n</code></pre>"},{"location":"#cli-options","title":"CLI Options","text":"<p>Whisper-TikTok supports the following command-line options:</p> <pre><code>python main.py [OPTIONS]\n\nOptions:\n  --model TEXT              Model to use [tiny|base|small|medium|large] (Default: small)\n  --non_english             Use general model, not the English one specifically. (Flag)\n  --url TEXT                YouTube URL to download as background video. (Default: &lt;https://www.youtube.com/watch?v=intRX7BRA90&gt;)\n  --tts TEXT                Voice to use for TTS (Default: en-US-ChristopherNeural)\n  --list-voices             Use `edge-tts --list-voices` to list all voices.\n--random_voice              Random voice for TTS (Flag)\n  --gender TEXT             Gender of the random TTS voice [Male|Female].\n  --language TEXT           Language of the random TTS voice(e.g., en-US)\n  --sub_format TEXT         Subtitle format to use [u|i|b] (Default: b) | b (Bold), u (Underline), i (Italic)\n  --sub_position INT        Subtitle position to use [1-9] (Default: 5)\n  --font TEXT               Font to use for subtitles (Default: Lexend Bold)\n  --font_color TEXT         Font color to use for subtitles in HEX format (Default: #FFF000).\n  --font_size INT           Font size to use for subtitles (Default: 21)\n  --max_characters INT      Maximum number of characters per line (Default: 38)\n  --max_words INT           Maximum number of words per segment (Default: 2)\n  --upload_tiktok           Upload the video to TikTok (Flag)\n  -v, --verbose             Verbose (Flag)\n</code></pre> <p>If you use the --random_voice option, please specify both --gender and --language arguments. Also you will need to specify the --non_english argument if you want to use a non-English voice otherwise the program will use the English model. Whisper model will auto-detect the language of the audio file and use the corresponding model.</p>"},{"location":"#usage-examples","title":"Usage Examples","text":"<ul> <li>Generate a TikTok video using a specific TTS model and voice:</li> </ul> <pre><code>python main.py --model medium --tts en-US-EricNeural\n</code></pre> <ul> <li>Generate a TikTok video without using the English model:</li> </ul> <pre><code>python main.py --non_english --tts de-DE-KillianNeural\n</code></pre> <ul> <li>Use a custom YouTube video as the background video:</li> </ul> <pre><code>python main.py --url https://www.youtube.com/watch?v=dQw4w9WgXcQ --tts en-US-JennyNeural\n</code></pre> <ul> <li>Modify the font color of the subtitles:</li> </ul> <pre><code>python main.py --sub_format b --font_color #FFF000 --tts en-US-JennyNeural\n</code></pre> <ul> <li>Generate a TikTok video with a random TTS voice:</li> </ul> <pre><code>python main.py --random_voice --gender Male --language en-US\n</code></pre> <ul> <li>List all available voices:</li> </ul> <pre><code>edge-tts --list-voices\n</code></pre>"},{"location":"#additional-resources","title":"Additional Resources","text":""},{"location":"#accelerate-video-creation","title":"Accelerate Video Creation","text":"<p>Contributed by @duozokker</p> <p>reddit2json is a Python script that transforms Reddit post URLs into a JSON file, streamlining the process of creating video.json files. This tool not only converts Reddit links but also offers functionalities such as translating Reddit post content using DeepL and modifying content through custom OpenAI GPT calls.</p>"},{"location":"#reddit2json-directly-convert-reddit-links-to-json","title":"reddit2json: Directly Convert Reddit Links to JSON","text":"<p>reddit2json is designed to process a list of Reddit post URLs, converting them into a JSON format that can be used directly for video creation. This tool enhances the video creation process by providing a faster and more efficient way to generate video.json files.</p> <p>Here is the detailed README for reddit2json which includes instructions for installation, setting up the .env file, example calls, and more.</p>"},{"location":"#code-of-conduct","title":"Code of Conduct","text":"<p>Please review our Code of Conduct before contributing to Whisper-TikTok.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>We welcome contributions from the community! Please see our Contributing Guidelines for more information.</p>"},{"location":"#upcoming-features","title":"Upcoming Features \ud83d\udd2e","text":"<ul> <li>Integration with the OpenAI API to generate more advanced responses.</li> <li>Generate content by extracting it from reddit https://github.com/MatteoFasulo/Whisper-TikTok/issues/22</li> </ul>"},{"location":"#acknowledgments","title":"Acknowledgments","text":"<ul> <li>We'd like to give a huge thanks to @rany2 for their edge-tts package, which made it possible to use the Microsoft Edge Cloud TTS API with Whisper-TikTok.</li> <li>We also acknowledge the contributions of the Whisper model by @OpenAI for robust speech recognition via large-scale weak supervision</li> <li>Also @jianfch for the stable-ts package, which made it possible to use the OpenAI Whisper model with Whisper-TikTok in a stable manner with font color and subtitle format options.</li> </ul>"},{"location":"#license","title":"License","text":"<p>Whisper-TikTok is licensed under the Apache License, Version 2.0.</p>"},{"location":"1-ffmpeg/","title":"Installing FFmpeg","text":"<p>FFmpeg is a powerful multimedia framework that provides command-line tools to record, convert, and stream audio and video. It's an essential tool for anyone working with multimedia files. In this guide, we'll walk you through the installation process for FFmpeg on various operating systems.</p>"},{"location":"1-ffmpeg/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Windows</li> <li>macOS</li> <li>Linux</li> <li>Testing Your FFmpeg Installation</li> </ol>"},{"location":"1-ffmpeg/#windows-installation","title":"Windows Installation","text":"<p>Installing FFmpeg on Windows can be done using pre-built executables.</p> <ol> <li> <p>Download FFmpeg: Visit the official FFmpeg website's download page at https://www.ffmpeg.org/download.html. Scroll down to the \"Windows\" section and choose one of the following options:</p> </li> <li> <p>Static Builds: These are recommended for most users. Download the latest \"64-bit\" or \"32-bit\" static build, depending on your system architecture.</p> </li> <li> <p>Other Builds: Advanced users can explore other options like linking libraries or shared builds.</p> </li> <li> <p>Extract the Zip File: Once the download is complete, extract the contents of the zip file to a location on your computer, e.g., <code>C:\\ffmpeg</code>. You should now have a folder containing FFmpeg executable files.</p> </li> <li> <p>Add FFmpeg to System Path (Optional): To use FFmpeg from any command prompt or terminal window, you can add its location to your system's PATH environment variable.</p> </li> <li> <p>Testing Installation: Open a command prompt and run the following command to verify your FFmpeg installation:</p> </li> </ol> <pre><code>ffmpeg -version\n</code></pre> <p>If installed correctly, this command will display FFmpeg's version information.</p>"},{"location":"1-ffmpeg/#macos-installation","title":"macOS Installation","text":"<p>You can install FFmpeg on macOS using package managers like Homebrew or MacPorts. Here's how to do it with Homebrew:</p> <ol> <li>Install Homebrew: If you don't already have Homebrew installed, open a terminal and run the following command:</li> </ol> <pre><code>/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n</code></pre> <ol> <li>Install FFmpeg: Once Homebrew is installed, you can install FFmpeg by running the following command:</li> </ol> <pre><code>brew install ffmpeg\n</code></pre> <ol> <li>Testing Installation: After installation, run the following command in your terminal to verify FFmpeg is correctly installed:</li> </ol> <pre><code>ffmpeg -version\n</code></pre> <p>You should see FFmpeg's version information.</p>"},{"location":"1-ffmpeg/#linux-installation","title":"Linux Installation","text":"<p>On Linux, you can install FFmpeg using your distribution's package manager. Here are instructions for some popular Linux distributions:</p>"},{"location":"1-ffmpeg/#ubuntudebian","title":"Ubuntu/Debian","text":"<ol> <li> <p>Open a terminal.</p> </li> <li> <p>Run the following commands to update your package list and install FFmpeg:</p> </li> </ol> <pre><code>sudo apt update\nsudo apt install ffmpeg\n</code></pre>"},{"location":"1-ffmpeg/#centosfedora","title":"CentOS/Fedora","text":"<ol> <li> <p>Open a terminal.</p> </li> <li> <p>Run the following command to install FFmpeg:</p> </li> </ol> <pre><code>sudo dnf install ffmpeg\n</code></pre>"},{"location":"1-ffmpeg/#arch-linux","title":"Arch Linux","text":"<ol> <li> <p>Open a terminal.</p> </li> <li> <p>Run the following command to install FFmpeg:</p> </li> </ol> <pre><code>sudo pacman -S ffmpeg\n</code></pre>"},{"location":"1-ffmpeg/#testing-installation","title":"Testing Installation","text":"<p>After installation, run the following command in your terminal to verify FFmpeg is correctly installed:</p> <pre><code>ffmpeg -version\n</code></pre> <p>You should see FFmpeg's version information.</p>"},{"location":"1-ffmpeg/#testing-your-ffmpeg-installation","title":"Testing Your FFmpeg Installation","text":"<p>To ensure FFmpeg is working correctly, you can run a simple test command. Open your command prompt, terminal, or PowerShell and run:</p> <pre><code>ffmpeg -version\n</code></pre> <p>This command should display FFmpeg's version information, confirming that FFmpeg is successfully installed on your system.</p> <p>Congratulations! You've now installed FFmpeg and can use its powerful multimedia capabilities for various tasks like video conversion, editing, and more.</p>"},{"location":"2-cuda/","title":"Installing CUDA Driver for GPU Acceleration","text":"<p>To harness the power of GPU acceleration for the OpenAI Whisper model with PyTorch, you'll need to install the CUDA driver on your system. CUDA is a parallel computing platform and API developed by NVIDIA that allows GPUs to perform complex computations much faster than traditional CPUs. This guide will walk you through the process of installing the CUDA driver step by step.</p>"},{"location":"2-cuda/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Prerequisites</li> <li>Installing CUDA Driver</li> <li>Verifying CUDA Installation</li> </ol>"},{"location":"2-cuda/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, make sure you have the following prerequisites in place:</p> <ul> <li> <p>A compatible NVIDIA GPU: CUDA requires an NVIDIA GPU that supports CUDA. You can check the list of supported GPUs on the NVIDIA website.</p> </li> <li> <p>Operating System: CUDA is available for various operating systems, including Windows, Linux, and macOS. Ensure you are using a supported OS.</p> </li> <li> <p>NVIDIA Driver: Make sure you have the latest NVIDIA driver installed for your GPU. You can download it from the official NVIDIA website.</p> </li> </ul>"},{"location":"2-cuda/#installing-cuda-driver","title":"Installing CUDA Driver","text":"<p>Follow these steps to install the CUDA driver on your system:</p>"},{"location":"2-cuda/#step-1-download-cuda-toolkit","title":"Step 1: Download CUDA Toolkit","text":"<ol> <li> <p>Visit the official NVIDIA CUDA Toolkit download page: https://developer.nvidia.com/cuda-downloads.</p> </li> <li> <p>Select your operating system and architecture. Choose the version that matches your system.</p> </li> <li> <p>Click the \"Download\" button to start the download.</p> </li> </ol>"},{"location":"2-cuda/#step-2-run-the-installer","title":"Step 2: Run the Installer","text":"<ol> <li> <p>Once the download is complete, run the CUDA Toolkit installer.</p> </li> <li> <p>Follow the on-screen instructions to install CUDA. You can customize the installation options, but it's recommended to install the default components unless you have specific requirements.</p> </li> <li> <p>During the installation, you may be prompted to install the NVIDIA driver if it's not already installed. Follow the prompts to complete the driver installation.</p> </li> <li> <p>CUDA will also prompt you to install the CUDA Toolkit and CUDA Samples. Install both components.</p> </li> </ol>"},{"location":"2-cuda/#step-3-environment-setup","title":"Step 3: Environment Setup","text":"<ol> <li> <p>After the installation is complete, you need to add CUDA to your system's PATH environment variable.</p> </li> <li> <p>Windows: CUDA will automatically add itself to the system PATH during installation. You may need to restart your computer for the changes to take effect.</p> </li> <li> <p>Linux: You can add CUDA to your PATH by appending the following line to your shell profile file (e.g., <code>~/.bashrc</code> or <code>~/.zshrc</code>):</p> <pre><code>export PATH=/usr/local/cuda/bin:$PATH\n</code></pre> </li> <li> <p>macOS: CUDA should also be added to your PATH automatically on macOS. Restart your terminal for the changes to apply.</p> </li> </ol>"},{"location":"2-cuda/#step-4-reboot-your-system","title":"Step 4: Reboot Your System","text":"<ol> <li>To ensure that the changes are applied correctly, it's recommended to reboot your system.</li> </ol>"},{"location":"2-cuda/#verifying-cuda-installation","title":"Verifying CUDA Installation","text":"<p>To verify that CUDA is installed correctly, follow these steps:</p> <ol> <li> <p>Open a terminal or command prompt.</p> </li> <li> <p>Run the following command to check the CUDA version:</p> </li> </ol> <pre><code>nvcc --version\n</code></pre> <p>This command should display the CUDA version, confirming that CUDA is installed.</p> <ol> <li>Additionally, you can run a GPU-related command, such as:</li> </ol> <pre><code>nvidia-smi\n</code></pre> <p>This command will display information about your NVIDIA GPU, including the driver version and GPU utilization.</p> <p>Congratulations! You've successfully installed the CUDA driver for GPU acceleration. You can now utilize the power of your GPU to accelerate tasks, including running the OpenAI Whisper model with PyTorch for faster and more efficient computations.</p>"},{"location":"3-docker/","title":"Docker Image for Whisper-TikTok","text":"<p>In this guide, we'll walk you through the process of using the dockerized version of the Whisper-TikTok model. Docker is a platform that allows you to package applications and their dependencies into containers, making it easy to run them on any system without worrying about compatibility issues.</p>"},{"location":"3-docker/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Prerequisites</li> <li>Pull the image</li> <li>Run the container</li> </ol>"},{"location":"3-docker/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, make sure you have Docker installed on your system. If you don't have Docker installed, you can follow the official installation guide to set it up.</p>"},{"location":"3-docker/#pull-the-image","title":"Pull the image","text":"<p>To use the Whisper-TikTok model in a Docker container, you first need to pull the Docker image from the ghcr repository. You can do this by running the following command in your terminal:</p> <pre><code>docker pull ghcr.io/matteofasulo/whisper-tiktok:main\n</code></pre> <p>This command will download the latest version of the Whisper-TikTok Docker image to your system.</p>"},{"location":"3-docker/#run-the-container","title":"Run the container","text":"<p>Once you have pulled the Docker image, you can run the container using the following command:</p> <pre><code>docker run -d --name whisper-tiktok --network host --mount source=whisper-tiktok-vol,target=/app ghcr.io/matteofasulo/whisper-tiktok:main\n</code></pre> <p>This command will start the Whisper-TikTok container in detached mode, using the host network and mounting a volume to store the model checkpoints and logs. You can now access the Whisper-TikTok API at <code>http://localhost:8000</code>.</p> <p>To stop the container, you can run the following command:</p> <pre><code>docker stop whisper-tiktok\n</code></pre> <p>And to remove the container, you can use:</p> <pre><code>docker rm whisper-tiktok\n</code></pre> <p>If you want to inspect the container volume to retrieve the output files, you can use the following command:</p> <pre><code>docker volume inspect whisper-tiktok-vol\n</code></pre> <p>This will provide you with the path to the volume on your system. Navigate to that path to access the model outputs.</p>"}]}